{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09845c1-25d2-4efe-b1f8-dd236e1baf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenizer:\n",
      "['This', 'is', 'the', 'first', 'paragraph', '.', 'It', 'has', 'two', 'sentences', '.', 'This', 'is', 'the', 'second', 'paragraph', '.', 'This', 'one', 'also', 'has', 'two', 'sentences', '.']\n",
      "\n",
      "Sentence Tokenizer:\n",
      "['\\nThis is the first paragraph.', 'It has two sentences.', 'This is the second paragraph.', 'This one also has two sentences.']\n",
      "\n",
      "Paragraph Tokenizer:\n",
      "['\\nThis is the first paragraph. It has two sentences.', 'This is the second paragraph. This one also has two sentences.\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Downloading required NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "def word_tokenizer(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def paragraph_tokenizer(text):\n",
    "    paragraphs = text.split('\\n\\n')  # Assuming paragraphs are separated by two newline characters\n",
    "    return paragraphs\n",
    "\n",
    "# Sample text for demonstration\n",
    "text = \"\"\"\n",
    "This is the first paragraph. It has two sentences.\n",
    "\n",
    "This is the second paragraph. This one also has two sentences.\n",
    "\"\"\"\n",
    "\n",
    "# Word Tokenization\n",
    "print(\"Word Tokenizer:\")\n",
    "print(word_tokenizer(text))\n",
    "\n",
    "# Sentence Tokenization\n",
    "print(\"\\nSentence Tokenizer:\")\n",
    "print(sentence_tokenizer(text))\n",
    "\n",
    "# Paragraph Tokenization\n",
    "print(\"\\nParagraph Tokenizer:\")\n",
    "print(paragraph_tokenizer(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70680c64-3b91-4a22-ae8b-f30840c9033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 49\n",
      "Distinct Words: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data files (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def analyze_corpus(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Count total words\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # Find distinct words by converting to a set\n",
    "    distinct_words = set(words)\n",
    "    distinct_word_count = len(distinct_words)\n",
    "    \n",
    "    return total_words, distinct_word_count\n",
    "\n",
    "# Sample corpus text\n",
    "corpus_text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. In particular, it focuses on how to program computers to process and analyze large amounts of natural language data.\n",
    "\"\"\"\n",
    "\n",
    "# Analyze the corpus\n",
    "total_words, distinct_word_count = analyze_corpus(corpus_text)\n",
    "\n",
    "print(\"Total Words:\", total_words)\n",
    "print(\"Distinct Words:\", distinct_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55ce16-41e5-4c5c-9da3-e5031bbc40d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
